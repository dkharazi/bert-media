{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for generic data preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "# Import libraries for model selection and accuracy measures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Import BERT transformer libraries\n",
    "from torch.utils.data import Dataset\n",
    "from torch import tensor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertConfig,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_parquet('../data/cluster_articles.gzip')\n",
    "articles = articles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publication</th>\n",
       "      <th>content</th>\n",
       "      <th>party</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breitbart Launches ’Border Wall Construction C...</td>\n",
       "      <td>Milo</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>last weekend church confessed sin personal van...</td>\n",
       "      <td>right</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDF Airstrike Eliminates 4 Islamic State-Linke...</td>\n",
       "      <td>Breitbart Jerusalem</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>times israel reports israeli airstrike killed ...</td>\n",
       "      <td>right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oracle Funds Anti-Google Effort that Outs Hill...</td>\n",
       "      <td>Chriss W. Street</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>oracle corporation using deep financial resour...</td>\n",
       "      <td>right</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silicon Valley Urges Giving Election Day Off t...</td>\n",
       "      <td>Chriss W. Street</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>apparently worried populist movement led donal...</td>\n",
       "      <td>right</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illegal Migrant Abandoned in Desert Calls 911 ...</td>\n",
       "      <td>Bob Price</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>severely dehydrated illegal alien called 911 p...</td>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               author  \\\n",
       "0  Breitbart Launches ’Border Wall Construction C...                 Milo   \n",
       "1  IDF Airstrike Eliminates 4 Islamic State-Linke...  Breitbart Jerusalem   \n",
       "2  Oracle Funds Anti-Google Effort that Outs Hill...     Chriss W. Street   \n",
       "3  Silicon Valley Urges Giving Election Day Off t...     Chriss W. Street   \n",
       "4  Illegal Migrant Abandoned in Desert Calls 911 ...            Bob Price   \n",
       "\n",
       "  publication                                            content  party  \\\n",
       "0   Breitbart  last weekend church confessed sin personal van...  right   \n",
       "1   Breitbart  times israel reports israeli airstrike killed ...  right   \n",
       "2   Breitbart  oracle corporation using deep financial resour...  right   \n",
       "3   Breitbart  apparently worried populist movement led donal...  right   \n",
       "4   Breitbart  severely dehydrated illegal alien called 911 p...  right   \n",
       "\n",
       "   cluster  \n",
       "0       -1  \n",
       "1        4  \n",
       "2       13  \n",
       "3       -1  \n",
       "4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any articles without definitive clusters\n",
    "articles = articles[articles['cluster'] != -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize BERT Tokenizer and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Initialize BERT configurations\n",
    "dist_config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=25)\n",
    "\n",
    "# Implement pre-trained BERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=dist_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Data using DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize articles\n",
    "tokenized_articles = tokenizer(\n",
    "    text=articles['content'].tolist(),\n",
    "    return_tensors='pt',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=True\n",
    "    )\n",
    "\n",
    "# Extract tokenized input IDs\n",
    "tokenized_articles = tokenized_articles['input_ids']\n",
    "\n",
    "# Reformat cluster column as tensor\n",
    "ts_clusters = tensor(articles['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Training and Test Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24498 4324 24498 4324\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tokenized_articles,\n",
    "    ts_clusters,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=ts_clusters\n",
    "    )\n",
    "\n",
    "# Print lengths\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crreate custom Dataset with articles\n",
    "class ArticlesDataset(Dataset):\n",
    "    def __init__(self, embeddings, clusters):\n",
    "        self.encodings = embeddings\n",
    "        self.labels = clusters\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Reformat training data as PyTorch Dataset\n",
    "train_dataset = ArticlesDataset(X_train[0:5], y_train[0:5])\n",
    "\n",
    "# Reformat test data as PyTorch Dataset\n",
    "test_dataset = ArticlesDataset(X_test[0:1], y_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize BERT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training configurations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../bert_results',    # output directory\n",
    "    num_train_epochs=3,              # total # of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='../bert_logs',      # logging directory\n",
    ")\n",
    "\n",
    "# Implement Trainer object for training on articles and clusters\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=3.233351389567057, metrics={'train_runtime': 18.7907, 'train_samples_per_second': 0.16, 'total_flos': 3086101877760.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 17035, 'init_mem_cpu_peaked_delta': 2904, 'train_mem_cpu_alloc_delta': 158080, 'train_mem_cpu_peaked_delta': 48100})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train BERT\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.2612812519073486,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_runtime': 0.4099,\n",
       " 'eval_samples_per_second': 2.439,\n",
       " 'epoch': 3.0,\n",
       " 'eval_mem_cpu_alloc_delta': 54342,\n",
       " 'eval_mem_cpu_peaked_delta': 12160}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 12\n",
      "actual: 12\n"
     ]
    }
   ],
   "source": [
    "print('prediction: ' + str(np.argmax(trainer.predict(test_dataset).predictions)))\n",
    "print('actual: ' + str(trainer.predict(test_dataset).label_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go back a remove this: [0:5]\n",
    "    - Try this to fix the kernel issue https://stackoverflow.com/a/59949321/12777044\n",
    "- Go back and expand test dataset from a single point: [0:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
